Title: Metareviewer Instructions
Date: 2019-08-01
SkipNavBar: 1

### Questions?

Please send any questions to: ml4h.workshop.neurips.2020@gmail.com

### Goals for Meta-reviewing Process

The goal of the meta-reviewing process is fourfold:

1.  Summarize the opinions of the reviewers to aid in final decision making. Note that in addition to accept/reject, proceedings track submissions can also be offered the opportunity to resubmit a 4-page version of their work to the abstract track without going through re-review.

2.  Provide a summary of the reviews' salient points for the author, focusing specifically on what critical aspects are needed to improve the submission for acceptance and/or what key strengths led the meta-reviewer to recommend acceptance.

3.  Review the (limited) author responses and identify any reviews that have critical misunderstandings or should otherwise be disregarded in the final decision. Flag low-quality reviews for internal tracking and to give reviewers feedback on their review quality

4.  Highlight high-quality papers and reviews for consideration for ML4H's 2020 Best Thematic Submission, Best Newcomer Submission, and Top Reviewer awards.

### Meta-Reviewing Tasks

1.  Confirm that you are comfortable meta-reviewing all assigned papers.

2.  Complete meta-review form for each assigned paper. While there will not be a formal consensus building phase, if you are meta-reviewing a particularly divisive paper, you can contact the reviewers via HotCRP.

3.  [Proceedings Track Only] Rank your assigned papers using[ this spreadsheet template](https://docs.google.com/spreadsheets/d/1928LA5502bM3tX9TuhsqybKgvTiNPMOkA8pKOin1Rdc/edit?usp=sharing). Please make a copy of the template for your own papers. Come to the Zoom meeting on Oct 27th prepared to discuss any borderline papers. 

### Timeline

Sept. 28: Submission abstracts & titles due. 

Oct. 2: Submissions due.

Oct. 3: Reviews & Meta-reviews assigned. Reviewing period begins!

Oct. 9: Meta-review Swap Deadline (proceedings track only). If you do not feel comfortable meta-reviewing one of your assigned papers, please contact us and we will try to arrange a swap with another meta-reviewer.

Oct. 16 AoE: Review deadline. Emergency reviews assigned.

Oct. 18: Emergency reviews due.

Oct. 20: Limited author response due. Meta-reviewing begins. Meta-reviewers may contact reviewers through HotCRP to seek consensus on divisive papers.

Oct. 26: Meta-reviews due. Proceedings Track meta-reviewers send rankings to the organizing committee at ml4h.workshop.neurips.2020@gmail.com.

Oct 27: [Proceedings Track Only] Meta-reviewers attend zoom call to make final decisions.

Oct. 28: Final decisions released

### How do I look at reviews for a paper on HotCRP & write my meta-review?

After clicking on a paper, make sure that you select "Main" in the upper left hand corner. This will take you to a summary of all of the completed reviews and allow you to post comments and rate reviews. To write your meta-review, click on "Review" in the upper left hand corner.

### How do I contact reviewers via HotCRP?

If you are meta-reviewing a paper that has very divisive scores, you may contact the reviewers on HotCRP. To do so, click "add comment" when you are on the review page for the paper. Make sure to change the visibility of the comment to "Hidden from authors" to only send the comment to the reviewers on the paper. Note that because the reviewing timeline is so short, we do not have a formal consensus building stage. While we have told reviewers that they might be contacted, please use this option sparingly. 

### What counts as a good ML4H Paper/Abstract?

All meta-reviewers should refer to the guidelines on [how to write a good ML4H paper or extended abstract](https://ml4health.github.io/2020/pages/writing-guidelines.html). The criteria for the proceedings and abstracts tracks are distinct -- while both tracks require high quality submissions, the abstract submissions should also be judged on their likelihood to lead to a good discussion at the workshop. Note that works submitted to the Proceedings track can also be considered for consideration to the extended abstract track. Reviewers have been instructed to flag any works they think would be a good fit for this during review, which you can use to form your overall recommendation on this point.

In addition to the examples highlighted in the writing guidelines themselves, you may also peruse the full [ML4H 2019 proceedings](http://proceedings.mlr.press/v116/) and [ML4H 2019 arxiv index](https://arxiv.org/html/2002.01584) (abstract track) to gain a better sense of the works we aim to accept. Note in particular on the proceedings track some of ML4H's prior most heavily cited works, such as [Retina U-Net](http://proceedings.mlr.press/v116/jaeger20a.html) or [Generative Image Translation for Data Augmentation in Colorectal Histopathology Images](http://proceedings.mlr.press/v116/wei20a.html)

### Conflict Guidelines & Expertise Alignment

Please check ASAP that your assigned papers do not represent conflicts of interest and that you feel confident in serving as a meta-reviewer for a paper in this topic area. You should not recognize any paper you are reviewing as work done by someone you work closely with.

If you find a conflict or a paper you are not confident you can meta-review, please report it immediately via email: <ml4h.workshop.neurips.2020@gmail.com>

### Format & Anonymity Guidelines

Reviewers have been instructed to flag any anonymity violations (our process is fully double-blind) or gross violations of format. Such violations can play a role in your decision making process, but as a general rule we would rather accept a strong work that needs to adjust its formatting slightly, or has a minor, clearly unintentional anonymity violation than reject a work on a technicality.

### Confidentiality Guidelines

ML4H 2020 is adopting the same confidentiality guidelines as the main NeurIPS conference. Importantly, all aspects of the review process should be confidential. Do not discuss the submissions or reviews or use any ideas from the submissions in your own work until they are publicly available.

### Meta-reviewing Quota

Each meta-reviewer will be assigned no more than 10 submissions. We do not have a budget in place for emergency meta-reviewing, so if you are not confident you can serve in this role for up to 10 submissions, please let us know ASAP and we can find a replacement meta-reviewer instead. Note that the purpose of having meta-reviewers review a larger number of submissions is that decisions can thus be more reflective of the overall pool of submissions. Take our suggested acceptance rates (listed in the form) when reviewing your full set of recommendations to ensure if you deviate from these suggestions it is intentional and recognized.

### How are papers assigned?

Authors labeled each paper with a set of topic areas, and each meta-reviewer was asked to rank their topic areas of expertise. These topic areas are used to assign meta-reviewers to the most relevant papers possible.

### FAQ

-   Can meta-reviewers also be authors of papers or extended abstracts?

Yes. Though of course a meta-reviewer will not be assigned to review their own papers. That's a conflict of interest.

-   What if I don't have sufficient expertise to review a paper assigned to me?

While papers should provide enough background that nearly all meta-reviewers can provide a reasonable meta-review, we understand that occasionally a paper may fall far outside your area of expertise. If this happens, please contact ml4h.workshop.neurips.2020@gmail.com before October 9th.

## Meta-reviewer Form

1.  [Visible to Authors] Overall Recommendation

Strong Accept 

Submission is in the top 5% of all submissions. Reviewer would argue strongly for this paper. Very original work of high value to the community. This submission should be considered for an oral presentation at the workshop.

Accept 

Submission is in the top 30% (Abstract Track) / 15% (Proceedings Track) of all submissions. Reviewer would recommend it to a colleague.

Marginal Accept

I tend to vote for accepting this submission, but rejecting it would not be that bad. This should only be used sparingly (e.g., no more than 1 submission of your 10, 2 if you absolutely must)

Reject 

Work suffers from one or more of:

-   Off-topic content (no ML or no healthcare application)

-   Severe technical flaws

-   No novel contribution (results are known or trivial)

-   Extreme formatting violations (e.g. main paper not condensable into 8 pages)

1.  [Visible to Authors] Summary of Recommendation\
    Please provide a short (2-3 sentences) summary of your overall recommendation. If the reviewers had very polarizing scores, please comment here on how those were reflected in your recommendation.

2.  [Visible to Authors] Key Strengths\
    Please provide a short (2-3 sentences or a bulleted list) summary of the key strengths identified by reviewers.

3.  [Visible to Authors] Key Weaknesses\
    Please provide a short (2-3 sentences or a bulleted list) summary of the key weaknesses identified by reviewers. The purpose of this section, in particular for works you recommend to be rejected, is to provide the author with a list of the critical changes that would be needed for this work to be accepted.

4.  [Y/N/NA (this is an abstract track submission), Administrator Only] For Proceedings Track Only: Regardless of your overall recommendation, if this paper is rejected from the proceedings track, do you think a shortened, 4-page version of this paper should be accepted to the extended abstract track without re-review? yes/no.

The primary goal of the extended abstract track is to generate productive and interesting discussion amongst conference attendees. Creative, insightful, and/or potentially divisive contributions (even if less fully developed or not performant) make great additions to the abstract track.

1.  [Y/N Administrator Only]: Do you recommend this paper be considered for the "Best Thematic Paper" award?

2.  [Y/N Administrator Only]: Does your overall recommendation deviate significantly from reviewer scores, and if so, why (e.g. a reviewer fundamentally misunderstood the paper)?

3.  [Administrator Only]: List the review IDs of any exceptionally good reviews in a comma separated list. (e.g. If you are reviewing paper #83, review 83A and 83B might be exceptionally good). This will be used to flag reviewers for consideration for the "Best Reviewer" award.

4.  [Administrator Only]: List the review IDs of any exceptionally poor reviews in a comma separated list (e.g. If you are reviewing paper #83, review 83C might be poor).

5.  [Y/N Administrator Only]: I have reviewed the author response for this paper (if present). Note that author responses should only exist for a few papers.