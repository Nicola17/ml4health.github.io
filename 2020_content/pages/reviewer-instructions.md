Title: Reviewer Instructions
Date: 2019-08-01
SkipNavBar: 1

### Questions?

Please send any questions to: ml4h.workshop.neurips.2020@gmail.com 

### Timeline

Sept. 28: Submission abstracts & titles due. 

Oct. 2: Submissions due.

Oct. 3: Reviews assigned. Reviewing period begins!

Oct. 16 AoE: Review deadline. Emergency reviews assigned.

Oct. 18: Emergency reviews due.

Oct. 20: Limited author response due. Meta-reviewing begins. Meta-reviewers may contact reviewers through HotCRP to seek consensus on divisive papers.

Oct. 26th: Meta-reviews due

Oct. 28th: Final decisions released

### Goals for Reviewing Process

Similar to last year,  we will have two tracks at the ML4H workshop: a formal proceedings track for polished work with technical sophistication and clear healthcare impact as well as an extended abstract track for non-traditional research artifacts. Our goal in providing two tracks is to establish ML4H as a strong venue for publishing excellent ML4H work while also providing a forum for insightful discussion of creative and probing ideas.

A final but crucial goal is to give good feedback. Please do more than just give a numerical score! Be sure to list positive aspects of the paper, as well as a few constructive things the authors could improve for either a camera ready version (if accepted) or for resubmission elsewhere (if rejected).

### What counts as a good ML4H Paper/Abstract?

All reviewers should refer to the guidelines on [how to write a good ML4H paper or extended abstract](https://ml4health.github.io/2020/pages/writing-guidelines.html). The criteria for the proceedings and abstracts tracks are distinct -- while both tracks require high quality submissions, the abstract submissions should also be judged on their likelihood to lead to a good discussion at the workshop. Please refer to the writing guidelines document for exemplary submissions in each track.

### When should a paper switch to the abstract track? 

Works submitted to the Proceedings track can be considered for consideration to the extended abstract track. If you are reviewing a paper and think that a shortened 4-page version of the work would be strong enough to warrant consideration in the extended abstract track, make sure to select that option in the reviewer form on HotCRP.

Keep in mind that the primary goal of the extended abstract track is to generate productive and interesting discussion amongst conference attendees. Creative, insightful, and/or potentially divisive contributions (even if less fully developed or not performant) make great additions to the abstract track.  As a result, an extended abstract may not necessarily meet the same level of technical sophistication as a paper, as long as it meets the criteria of generating productive / interesting discussions.

### Confidentiality Guidelines

ML4H 2020 is adopting the same confidentiality guidelines as the main NeurIPS conference. Importantly, all aspects of the review process should be confidential. Do not discuss the submissions or reviews or use any ideas from the submissions in your own work until they are publicly available.

### Conflict Guidelines

Please check ASAP that your assigned papers do not represent conflicts of interest. You should not recognize any paper you are reviewing as work done by someone you work closely with.

If you find a conflict, report it immediately via email: <ml4h.workshop.neurips.2020@gmail.com>

### Anonymity Guidelines

Papers should be anonymous. If you find a major violation, please report it to the organizers: ml4h.workshop.neurips.2020@gmail.com.

Our process is double-blind. The authors do not know the reviewers' identities, and the reviewers do not know the authors' identities.  Of course, no process is perfect: the reviewers might be able to guess the authors' identities based on the data set or the approaches used, or by technical reports posted on the internet.  As a reviewer, we expect you will not actively attempt to discover the identity of the author.  We also caution you against assuming that you've discovered an author's identity based on a data set or approach: multiple independent invention is common, and different groups often share data sets. 

### Formatting Guidelines

Proceedings track papers should have their main content limited to 9 pages (including figures and text, but excluding references), and extended abstracts should be limited to 4 pages. Both submissions should use the two-column, PMLR, style file. See our [official instructions](https://ml4health.github.io/2020/pages/call-for-participation.html).

Please note that:

-   Papers (abstracts) with references that go beyond 9 (4) pages are allowed.

-   Papers (abstracts) with appendices that go beyond 9 (4) pages are allowed. However, reviewers should not feel obligated to read any supplementary material. Your time is precious!

-   Papers that do not use the PMLR style, but otherwise have content within page limit that could easily be made into the right format, are probably OK.

In general, we'd rather accept good work than nitpick about little formatting issues (especially because some clinicians may not be familiar with LaTeX). But big issues (e.g. a 20 page journal-like paper) would be grounds for rejection.

### How many reviews?

We've tried our best to grow a large pool of reviewers, so that each reviewer will be assigned no more than 5 submissions. Please help us keep this number small by completing your assigned reviews on time -- and if you can complete them early, all the better!

### How are papers assigned?

Authors labeled each paper with a set of topic areas, and each reviewer was asked to list their topic areas of expertise. These topic areas were used to assign reviewers to the most relevant papers possible.

Our reviewers all have expertise in both ML and healthcare applications. We used prior reviewing experience as well as training level to pair less experienced reviewers with more experienced reviewers.

### FAQ

-   Can PC members also be authors of papers or extended abstracts?

Yes. Though of course a PC member will not be assigned to review their own papers. That's a conflict of interest.

-   What if I don't have sufficient expertise to review a paper assigned to me?

While papers should provide adequate background that nearly all reviewers can provide a reasonable review, we understand that occasionally a paper may fall far outside your area of expertise. If this happens, please contact ml4h.workshop.neurips.2020@gmail.com immediately.

## Reviewer Form

### Full Papers

***Summary***

1.  Please provide a 2-3 sentence summary of the work.

***Technical Sophistication***

1.  What is your assessment of the technical sophistication of the work (please rate from 1-5)?

5  =  very positive 

4  =  positive

3  =  neutral 

2  =  negative 

1  =  very negative

1.  Please provide comments on the technical sophistication of the work.

Are the methods well motivated? Are there appropriate baselines? Is the evaluation technically sound?

***Relevance to Healthcare***

1.  What is your assessment of the work's relevance to healthcare (please rate from 1-5)?

2.  Please provide comments on the work's relevance to healthcare.

Does this paper address a meaningful problem in healthcare? Do the authors exhibit understanding of key domain considerations relevant to the work (could include: understanding clinical bottlenecks, systemic biases in specific data sources, etc.)

***Significance***

1.  What is your assessment of the significance of the work (please rate from 1-5)?

2.  Please provide comments on the work's significance.

Do the authors clearly describe how this paper relates to existing work in the field? Does the work represent a significant computational or biomedical advance?

***Presentation***

1.  What is your assessment of the quality of the presentation (please rate from 1-5)? 

2.  Please provide comments on the presentation of the work. 

Are methods described in sufficient detail? Are figures relevant, compelling, and legible? Are the motivating problem(s) and contributions clear?

***Overall***

1.  [Y/N/NA] Statistical Analysis: In our submission form question "Statistical Analysis" we asked authors to report how their results were validated statistically. Is their answer accurate as compared to what they report in the paper?\
    To see the submission form questions, scroll to the top of the page in the "Submission" block, above the "Edit Review" block, and look at the provided answers there.

2.  [Y/N/NA] Source of Variance: In our submission form (for select submissions), we asked authors to report what source of variance they leveraged to perform their statistical analysis in the question "Source of Variance". Is their answer accurate as compared to what they report in the paper? If this question is not present, select "Not Applicable."

3.  [Y/N/NA]: Multi-site Validation: In our submission form question "Multi-site Validation" we asked authors to report whether or not their method was evaluated on clinical data from multiple sites. Is their answer accurate as compared to what they report in the paper?

4.  [Y/N/NA] Comparisons to Baselines: In our submission form question "Comparisons to Baselines" we asked authors to report on what baselines to which they compare their model. Is their answer accurate as compared to what they report in the paper?

5.  [Y/N/NA] Interpretability: In our submission form question "Interpretability" we asked authors to report whether or not they performed any interpretability analyses of their model/results. Is their answer accurate as compared to what they report in the paper?

6.  Please provide any overall comments on the work, including but not limited to a list of key strengths and weaknesses of the work.

7.  Please make a recommendation

Strong Accept

Paper is in the top 5% of all submissions. Reviewer would argue strongly for this paper. Very original work of high value to the community. This paper should be considered for an oral presentation at the workshop.

Accept 

Paper is in the top 15% of all submissions. Reviewer would recommend it to a colleague.

Marginal Accept

 I tend to vote for accepting this submission, but rejecting it would not be that bad.

Marginal Reject

I tend to vote for rejecting this submission, but accepting it would not be that bad.

Reject 

Work suffers from one or more of:

-   Off-topic content (no ML or no healthcare application)

-   Severe technical flaws

-   No novel contribution (results are known or trivial)

-   Extreme formatting violations (e.g. main paper not condensable into 8 pages)

1.  Please indicate your confidence in this assessment

5: Absolutely Certain

You are absolutely certain about your assessment. You are very familiar with the related work.

4: Confident

You are confident in your assessment, but not absolutely certain.It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.

3: Fairly Confident

You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.

2: Mildly confident

You are willing to defend your assessment, but it is quite likely that you did not understand central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.

1: Not confident

Your assessment is an educated guess.The submission is not in your area or the submission was difficult to understand. Math/other details were not carefully checked.

1.  Regardless of your overall recommendation, if this submission is rejected from the proceedings track, to what extent do you think a shortened, 4-page version of this submission should be accepted to the extended abstract track without re-review?

The primary goal of the extended abstract track is to generate productive and interesting discussion amongst conference attendees. Creative, insightful, and/or potentially divisive contributions (even if less fully developed or not performant) make great additions to the abstract track.

1.  No, this submission would be inappropriate and/or insufficient for either track.

2.  No, this submission is too technically dense to permit a meaningful 4-page shortened submission.

3.  Yes, this paper could be condensed and would be a reasonable acceptance to the abstract track.

4.  Yes, this paper could be condensed and is exemplary of the abstract track's distinct goals.

1.  [Visible only to administrators] Do you think this submission is a strong example of this year's theme ("Advancing Healthcare for All?"), and, if so, why? If you do not think this submission is a strong example of the theme, simply leave this field blank.

This information will be used to help shortlist papers for the Best Thematic Paper award.

### Extended Abstracts

***Summary***

1.  Please provide a 2-3 sentence summary of the work.

***Contribution to the workshop***

1.  What is your assessment of the contribution of this extended abstract to the workshop (please rate from 1-5)?

5  =  very positive 

4  =  positive

3  =  neutral 

2  =  negative 

1  =  very negative

1.  In what ways would this work be valuable to other attendees of the workshop?

Would this work generate fruitful discussion? Are technical innovations (if applicable) not only correct, but particularly creative or generalizable to other application areas?  Does the work highlight pitfalls that are broadly applicable? Is the work likely to spur productive collaborations between researchers from different backgrounds?

***Relevance to Healthcare***

1.  What is your assessment of the work's relevance to healthcare (please rate from 1-5)?

2.  Please provide comments on the work's relevance to healthcare.

Does this paper address a meaningful problem in healthcare, or could this paper realistically lead to meaningful improvements in healthcare in the future? Do the authors exhibit understanding of key domain considerations relevant to the work (could include: understanding clinical bottlenecks, systemic biases in specific data sources, etc.)

***Presentation***

1.  What is your assessment of the quality of the presentation of the work (please rate from 1-5)? 

2.  Please provide comments on the presentation of the work. 

Are methods described in sufficient detail? Are figures relevant, compelling, and legible? Are the motivating problem and contributions clear?

***Overall***

1.  [Y/N/NA] Statistical Analysis: In our submission form question "Statistical Analysis" we asked authors to report how their results were validated statistically. Is their answer accurate as compared to what they report in the paper?

2.  [Y/N/NA] Source of Variance: In our submission form (for select submissions), we asked authors to report what source of variance they leveraged to perform their statistical analysis in the question "Source of Variance". Is their answer accurate as compared to what they report in the paper? If this question is not present, select "Not Applicable."

3.  [Y/N/NA]: Multi-site Validation: In our submission form question "Multi-site Validation" we asked authors to report whether or not their method was evaluated on clinical data from multiple sites. Is their answer accurate as compared to what they report in the paper?

4.  [Y/N/NA] Comparisons to Baselines: In our submission form question "Comparisons to Baselines" we asked authors to report on what baselines to which they compare their model. Is their answer accurate as compared to what they report in the paper?

5.  [Y/N/NA] Interpretability: In our submission form question "Interpretability" we asked authors to report whether or not they performed any interpretability analyses of their model/results. Is their answer accurate as compared to what they report in the paper?

6.  Please provide any overall comments on the work, including but not limited to a list of key strengths and weaknesses of the work.

7.  Please make a recommendation

Strong Accept 

Extended abstract is in the top 5% of all submissions. Reviewer would argue strongly for this extended abstract. Very original work of high value to the community.  This extended abstract should be considered for an oral presentation at the workshop, if possible.

Accept 

Extended abstract is in the top 15% of all submissions. Reviewer would recommend it to a colleague.

Marginal Accept

I tend to vote for accepting this submission, but rejecting it would not be that bad.

Marginal Reject

I tend to vote for rejecting this submission, but accepting it would not be that bad.

Reject 

Work suffers from one or more of:

-   Off-topic content (no ML or no healthcare application)

-   Severe technical flaws

-   No novel contribution (results are known or trivial)

-   Extreme formatting violations (e.g.  not condensable into 4 pages)

1.  Please indicate your confidence in this assessment

5: Absolutely Certain

You are absolutely certain about your assessment. You are very familiar with the related work.

4: Confident

You are confident in your assessment, but not absolutely certain.It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.

3: Fairly Confident

You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.

2: Mildly confident

You are willing to defend your assessment, but it is quite likely that you did not understand central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.

1: Not confident

Your assessment is an educated guess.The submission is not in your area or the submission was difficult to understand. Math/other details were not carefully checked.

1.  Y/N: Do you think this submission is a strong example of this year's theme ("Advancing Healthcare for All?"), and, if so, why? If you do not think this submission is a strong example of the theme, simply leave this field blank.

This information will be used to help shortlist papers for the Best Thematic Paper award.